{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "mount_file_id": "1rWgQ-B5psX3GWjT4zCguhgKdOZtk19nb",
      "authorship_tag": "ABX9TyNS6vA/hqTnZbdU1/Y5Tltn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NiclasFenton-Wiegleb/schlager-lyrics-bot/blob/main/Schlage_bot_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I1aLVqVczjQY"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.3\n",
        "!pip install datasets\n",
        "!pip install peft\n",
        "!pip install accelerate\n",
        "!pip install bitsandbytes\n",
        "!pip install trl\n",
        "!pip install safetensors\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check CUDA is running on GPU\n",
        "\n",
        "import torch\n",
        "print(torch.cuda.is_available(), torch.cuda.is_bf16_supported())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZyU7ckG9zx-",
        "outputId": "36fd9b68-8e24-47b0-96d4-0404f98360a4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import dependencies\n",
        "\n",
        "from random import randrange\n",
        "import pandas as pd\n",
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "xddoxWiZz9qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_lyrics = pd.read_csv('schlager_songs_v2.csv')\n",
        "\n",
        "df_lyrics['lyrics'][10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "XRn7gvV20CsC",
        "outputId": "ba83ca9b-0cb0-414b-e450-714446d6a139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"status\"false,\"reason\"\"Unexpected error occurred (no quota cost) Please try again later\"}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create separate column for 1st verse\n",
        "\n",
        "verse_list = []\n",
        "\n",
        "for ind in df_lyrics[\"lyrics\"].index:\n",
        "    lyrics = df_lyrics[\"lyrics\"].iloc[ind]\n",
        "    if lyrics == '{\"status\"false,\"reason\"\"Unexpected error occurred (no quota cost) Please try again later\"}' :\n",
        "        verse_list.append(None)\n",
        "    else:\n",
        "        try:\n",
        "            verse = lyrics.split(\"\\n\")[0]\n",
        "            n = 1\n",
        "            while len(' '.join(verse).split()) <= 15:\n",
        "                verse = lyrics.split(\"\\n\")[0:n]\n",
        "                n += 1\n",
        "            verse_list.append(''.join(verse))\n",
        "\n",
        "        except:\n",
        "            verse_list.append(None)\n",
        "\n",
        "\n",
        "df_lyrics[\"verse_1\"] = verse_list\n",
        "\n",
        "df_lyrics[\"verse_1\"][0]\n",
        "\n",
        "df_lyrics.to_csv(\"schlager_songs_v2.csv\")"
      ],
      "metadata": {
        "id": "8mtY_ZL706gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt Example\n",
        "\n",
        "### Instruction:\n",
        "\n",
        "\"Benuzte den unten gegebenen Vers um den Text für ein Lied zu schreiben.\"\n",
        "\n",
        "### Input:\n",
        "\n",
        "\"Du sagst nicht ein Wort\"\n",
        "\n",
        "### Response:\n",
        "\n",
        "f\"\"\" Du sagst nicht ein Wort\n",
        " Und deine Hand wischt eine Träne fort\n",
        " Und dein leerer Blick\n",
        " Sinkt in dein Glas\n",
        " Du sitzt hier vor mir\n",
        " Und dein Gesicht lässt keinen Zweifel mehr\n",
        " Heut sagst du mir\n",
        " Dass ich dich verlier'\n",
        " Nie war Zeit für dich\n",
        " Ich lebte nur in meiner eignen Welt\n",
        " Ich weiß, du wirst gehen\n",
        " Ich muss dich versteh'n\n",
        " Lieb mich ein letztes mal\n",
        " Es bleibt mir keine andre Wahl\n",
        " Ich weiß, dass ich die Nacht mit dir\n",
        " An den Tag verlier'\n",
        "...\n",
        " Und bleib bei mir\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "R6V6mFcD0-TM",
        "outputId": "93a7e63c-d9b9-4b65-eb48-de9437095c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Du sagst nicht ein Wort\\n Und deine Hand wischt eine Träne fort\\n Und dein leerer Blick\\n Sinkt in dein Glas\\n Du sitzt hier vor mir\\n Und dein Gesicht lässt keinen Zweifel mehr\\n Heut sagst du mir\\n Dass ich dich verlier'\\n Nie war Zeit für dich\\n Ich lebte nur in meiner eignen Welt\\n Ich weiß, du wirst gehen\\n Ich muss dich versteh'n\\n Lieb mich ein letztes mal\\n Es bleibt mir keine andre Wahl\\n Ich weiß, dass ich die Nacht mit dir\\n An den Tag verlier'\\n...\\n Und bleib bei mir\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_instruction(sample):\n",
        "    return f\"\"\"### Instruction:\n",
        "Benuzte den unten gegebenen Vers um den Text für ein Lied zu schreiben.\n",
        "\n",
        "### Input:\n",
        "\n",
        "{sample['input']}\n",
        "\n",
        "### Response:\n",
        "\n",
        "{sample['output']}\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "fsUKzUef1BU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create input and output dataset from dataframe\n",
        "\n",
        "df_dataset = df_lyrics[[\"verse_1\", \"lyrics\"]]\n",
        "\n",
        "ind_nan = []\n",
        "\n",
        "for ind in df_dataset.index:\n",
        "    if df_dataset[\"verse_1\"].iloc[ind] == None:\n",
        "        ind_nan.append(ind)\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "df_dataset.drop(index=ind_nan, inplace=True)\n",
        "\n",
        "df_dataset.reset_index(drop=True, inplace=True)\n",
        "\n",
        "df_dataset.rename(columns={\"lyrics\" : \"output\", \"verse_1\" : \"input\"}, inplace= True)\n",
        "\n",
        "dataset = Dataset.from_pandas(df_dataset)\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POcra1uT1Eyz",
        "outputId": "9377a19d-1981-450f-ccc1-291d56b8289c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-50f732c958cc>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_dataset.drop(index=ind_nan, inplace=True)\n",
            "<ipython-input-8-50f732c958cc>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_dataset.rename(columns={\"lyrics\" : \"output\", \"verse_1\" : \"input\"}, inplace= True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input', 'output'],\n",
              "    num_rows: 1046\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(format_instruction(dataset[randrange(len(dataset))]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4rZvR4x1KM5",
        "outputId": "cc25f385-6741-4c1f-9e9b-b142fd3afa8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction:\n",
            "Benuzte den unten gegebenen Vers um den Text für ein Lied zu schreiben.\n",
            "\n",
            "### Input:\n",
            "\n",
            " Ein Tag wie jeder, ich träum' von Liebe\n",
            "\n",
            "### Response:\n",
            "\n",
            " Ein Tag wie jeder, ich träum' von Liebe\n",
            " Doch eben nur ein Traum, aha, aha\n",
            " Menschen wohin ich schau', Großstadtgetriebe\n",
            " Und auf einmal sah ich sie, sie\n",
            "  Jahr', blondes Haar, so stand sie vor mir (woahoh)\n",
            "  Jahr', blondes Haar, wie find' ich zu ihr?\n",
            " Lalala, lalala, lalalalala\n",
            " Sie hat mich angelacht und war vorüber\n",
            " Da war's um mich geschehen, aha, aha\n",
            " Menschen wohin ich schau', Großstadtgetriebe\n",
            " Und überall such ich sie, sie\n",
            "  Jahr', blondes Haar, so stand sie vor mir (woahoh)\n",
            "  Jahr', blondes Haar, wie find' ich zu ihr?\n",
            " Lalala, lalala, lalalalala\n",
            " Lalala, lalala, lalalalala\n",
            "  Jahr', blondes Haar, so stand sie vor mir (woahoh)\n",
            "  Jahr', blondes Haar, wie find' ich zu ihr?\n",
            "  Jahr', blondes Haar, so stand sie vor mir\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dependencies\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "import accelerate\n",
        "\n",
        "#SFTTrainer supports a native integration with peft, which makes it easy to instruction tune LLMs\n",
        "\n",
        "from peft import LoraConfig, get_peft_model #, prepare_model_for_kbit_training"
      ],
      "metadata": {
        "id": "fhA4j8iM1NT5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "15e4c0c1-47ac-4325-856b-e123739e69b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-26ad6ed7c456>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBitsAndBytesConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtrl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFTTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccelerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextEnvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTextHistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBestOfNSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimport_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_diffusers_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_peft_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_wandb_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m from .models import (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trl/extras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# See the License for the specific language governing permissions and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbest_of_n_sampler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBestOfNSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trl/extras/best_of_n_sampler.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSUPPORTED_ARCHITECTURES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPreTrainedModelWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trl/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# See the License for the specific language governing permissions and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodeling_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreTrainedModelWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_reference_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodeling_value_head\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForCausalLMWithValueHead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForSeq2SeqLMWithValueHead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trl/models/modeling_base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_peft_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     from peft import (\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mLoraConfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mPeftConfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'prepare_model_for_kbit_training' from 'peft' (/usr/local/lib/python3.10/dist-packages/peft/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hugging Face model id\n",
        "model_id = \"malteos/bloom-6b4-clp-german\" # non-gated\n",
        "\n",
        "\n",
        "# BitsAndBytesConfig int-4 config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "      model_id,\n",
        "      quantization_config=bnb_config,\n",
        "      use_cache=False,\n",
        "      device_map=\"auto\")\n",
        "model.config.pretraining_tp = 1\n"
      ],
      "metadata": {
        "id": "WO2DbO441Vea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "id": "CeBa_zV91ac8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LoRA config based on QLoRA paper\n",
        "peft_config = LoraConfig(\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.1,\n",
        "        r=64,\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "\n",
        "# prepare model for training\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "model = get_peft_model(model, peft_config)"
      ],
      "metadata": {
        "id": "YEOJD6ab1eAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We need to define the hyperparameters before we can start training\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./content/drive/MyDrive/AiCore/trained_model/New folder\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size= 4,\n",
        "    gradient_accumulation_steps=2,\n",
        "    gradient_checkpointing=True,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-4,\n",
        "    bf16=True,\n",
        "    tf32=True,\n",
        "    max_grad_norm=0.3,\n",
        "    warmup_ratio=0.03,\n",
        "    lr_scheduler_type=\"constant\",\n",
        "    disable_tqdm=True  # disable tqdm since with packing values are in correct\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        },
        "id": "rUdJzW0mDM-B",
        "outputId": "ed9f8755-5f90-448b-cf38-40eaa3b0ffea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-54e41f0768e2>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#We need to define the hyperparameters before we can start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m args = TrainingArguments(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./content/drive/MyDrive/AiCore/trained_model/New folder\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, sharded_ddp, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, datalo...\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1374\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_bf16_gpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                         \u001b[0;31m# gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m                         raise ValueError(\n\u001b[0m\u001b[1;32m   1377\u001b[0m                             \u001b[0;34m\"Your setup doesn't support bf16/gpu. You need torch>=1.10, using Ampere GPU with cuda>=11.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m                         )\n",
            "\u001b[0;31mValueError\u001b[0m: Your setup doesn't support bf16/gpu. You need torch>=1.10, using Ampere GPU with cuda>=11.0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We can now configure the trainer\n",
        "\n",
        "max_seq_length = 2048 # max sequence length for model and packing of the dataset\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=peft_config,\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    packing=True,\n",
        "    formatting_func=format_instruction,\n",
        "    args=args,\n",
        ")"
      ],
      "metadata": {
        "id": "DxBNY_LNDQEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "trainer.train() # there will not be a progress bar since tqdm is disabled\n",
        "\n",
        "# save model\n",
        "trainer.save_model()"
      ],
      "metadata": {
        "id": "6IR7a-rIDV2a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}